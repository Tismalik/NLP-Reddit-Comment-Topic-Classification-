{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling - Evaluation:\n",
    "<h3> In this Notebook i'll first split the dataframe which now contains the wordembedding vector representation for \n",
    " the comment and topic columns, into Training and Test set at 70:30 </h3>\n",
    "\n",
    "<h3> Next: We'll apply the following models \"listed below\" to our data and then use accuracy to measure the model with the best performance \n",
    "    <p>The chossen model will then be Tested on unseen data and  explored using other Evaluation Metrics.</p>\n",
    "    <p>S/N: Elements of Grid Search are be used to tune Hyperparameter for MLP</P>\n",
    "</h3>\n",
    "\n",
    "<p>\n",
    "<ul>\n",
    "    <li> Support Vector Machine</li>\n",
    "    <li> Logistic Regression (X) </li>\n",
    "    <li> RandomForest</li>\n",
    "    <li> XGBoost / LSTM Neural Network / MLP </li>\n",
    "    <li> Naive Bayes (X)</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "<h3> Here are some evaluation metric we'll be using for the model</h3>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> F1 score</li>\n",
    "    <li> Accuracy </li>\n",
    "    <li> Precision</li>\n",
    "    <li> Recall </li>\n",
    "    <li> Confusion Matrix</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>90.1</th>\n",
       "      <th>91.1</th>\n",
       "      <th>92.1</th>\n",
       "      <th>93.1</th>\n",
       "      <th>94.1</th>\n",
       "      <th>95.1</th>\n",
       "      <th>96.1</th>\n",
       "      <th>97.1</th>\n",
       "      <th>98.1</th>\n",
       "      <th>99.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>-0.034674</td>\n",
       "      <td>0.180679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.093612</td>\n",
       "      <td>0.134560</td>\n",
       "      <td>-0.090816</td>\n",
       "      <td>-0.093931</td>\n",
       "      <td>0.006347</td>\n",
       "      <td>0.067203</td>\n",
       "      <td>-0.296446</td>\n",
       "      <td>0.236455</td>\n",
       "      <td>0.319731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180729</td>\n",
       "      <td>-0.034253</td>\n",
       "      <td>-0.007357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021574</td>\n",
       "      <td>0.278756</td>\n",
       "      <td>0.060132</td>\n",
       "      <td>-0.295516</td>\n",
       "      <td>-0.123788</td>\n",
       "      <td>0.117804</td>\n",
       "      <td>-0.156616</td>\n",
       "      <td>-0.108647</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.123385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014433</td>\n",
       "      <td>-0.187421</td>\n",
       "      <td>0.032284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225268</td>\n",
       "      <td>0.101662</td>\n",
       "      <td>-0.002514</td>\n",
       "      <td>-0.092069</td>\n",
       "      <td>-0.191231</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>-0.048874</td>\n",
       "      <td>-0.169493</td>\n",
       "      <td>0.404920</td>\n",
       "      <td>0.206606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102713</td>\n",
       "      <td>-0.122163</td>\n",
       "      <td>0.167701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075651</td>\n",
       "      <td>0.053715</td>\n",
       "      <td>0.042065</td>\n",
       "      <td>-0.074095</td>\n",
       "      <td>-0.325612</td>\n",
       "      <td>-0.029785</td>\n",
       "      <td>0.063639</td>\n",
       "      <td>0.030749</td>\n",
       "      <td>0.490816</td>\n",
       "      <td>0.076445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123185</td>\n",
       "      <td>-0.057500</td>\n",
       "      <td>0.164821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220945</td>\n",
       "      <td>0.070169</td>\n",
       "      <td>-0.045384</td>\n",
       "      <td>-0.023608</td>\n",
       "      <td>-0.403638</td>\n",
       "      <td>-0.047966</td>\n",
       "      <td>0.021852</td>\n",
       "      <td>-0.119835</td>\n",
       "      <td>0.352950</td>\n",
       "      <td>0.071742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045362</td>\n",
       "      <td>-0.110592</td>\n",
       "      <td>-0.060787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083572</td>\n",
       "      <td>0.117578</td>\n",
       "      <td>-0.050548</td>\n",
       "      <td>-0.240905</td>\n",
       "      <td>-0.065884</td>\n",
       "      <td>0.097666</td>\n",
       "      <td>-0.186384</td>\n",
       "      <td>-0.357412</td>\n",
       "      <td>0.373521</td>\n",
       "      <td>0.311909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135307</td>\n",
       "      <td>-0.096323</td>\n",
       "      <td>-0.107072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041132</td>\n",
       "      <td>0.226143</td>\n",
       "      <td>-0.060794</td>\n",
       "      <td>-0.271573</td>\n",
       "      <td>-0.233932</td>\n",
       "      <td>0.017458</td>\n",
       "      <td>0.101868</td>\n",
       "      <td>0.061758</td>\n",
       "      <td>0.432194</td>\n",
       "      <td>0.132932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.003029</td>\n",
       "      <td>-0.035019</td>\n",
       "      <td>-0.003800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176898</td>\n",
       "      <td>0.235542</td>\n",
       "      <td>-0.309587</td>\n",
       "      <td>-0.118536</td>\n",
       "      <td>-0.236206</td>\n",
       "      <td>0.157906</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>-0.052904</td>\n",
       "      <td>0.599252</td>\n",
       "      <td>-0.017703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.018971</td>\n",
       "      <td>-0.178611</td>\n",
       "      <td>-0.049338</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021237</td>\n",
       "      <td>0.263314</td>\n",
       "      <td>-0.019418</td>\n",
       "      <td>-0.325118</td>\n",
       "      <td>-0.068818</td>\n",
       "      <td>-0.095046</td>\n",
       "      <td>0.113397</td>\n",
       "      <td>0.029055</td>\n",
       "      <td>0.335391</td>\n",
       "      <td>0.223715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>neu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116796</td>\n",
       "      <td>-0.178244</td>\n",
       "      <td>0.107261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023487</td>\n",
       "      <td>0.140248</td>\n",
       "      <td>0.096510</td>\n",
       "      <td>-0.230313</td>\n",
       "      <td>-0.297580</td>\n",
       "      <td>-0.073714</td>\n",
       "      <td>-0.069468</td>\n",
       "      <td>-0.119313</td>\n",
       "      <td>0.249925</td>\n",
       "      <td>0.050214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3259 rows Ã— 307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target    a    b    c    d    e    f         0         1         2  ...  \\\n",
       "0       neu  0.0  1.0  0.0  1.0  0.0  0.0  0.006560 -0.034674  0.180679  ...   \n",
       "1       pos  0.0  0.0  1.0  0.0  1.0  0.0  0.180729 -0.034253 -0.007357  ...   \n",
       "2       pos  0.0  0.0  1.0  0.0  1.0  0.0  0.014433 -0.187421  0.032284  ...   \n",
       "3       pos  1.0  0.0  0.0  1.0  0.0  0.0  0.102713 -0.122163  0.167701  ...   \n",
       "4       pos  1.0  0.0  0.0  1.0  0.0  0.0  0.123185 -0.057500  0.164821  ...   \n",
       "...     ...  ...  ...  ...  ...  ...  ...       ...       ...       ...  ...   \n",
       "3254    neg  1.0  0.0  0.0  0.0  1.0  0.0  0.045362 -0.110592 -0.060787  ...   \n",
       "3255    neg  1.0  0.0  0.0  0.0  1.0  0.0  0.135307 -0.096323 -0.107072  ...   \n",
       "3256    neg  1.0  0.0  0.0  0.0  0.0  1.0 -0.003029 -0.035019 -0.003800  ...   \n",
       "3257    neg  1.0  0.0  0.0  0.0  1.0  0.0 -0.018971 -0.178611 -0.049338  ...   \n",
       "3258    neu  0.0  1.0  0.0  1.0  0.0  0.0  0.116796 -0.178244  0.107261  ...   \n",
       "\n",
       "          90.1      91.1      92.1      93.1      94.1      95.1      96.1  \\\n",
       "0     0.132200  0.093612  0.134560 -0.090816 -0.093931  0.006347  0.067203   \n",
       "1     0.021574  0.278756  0.060132 -0.295516 -0.123788  0.117804 -0.156616   \n",
       "2     0.225268  0.101662 -0.002514 -0.092069 -0.191231  0.003927 -0.048874   \n",
       "3     0.075651  0.053715  0.042065 -0.074095 -0.325612 -0.029785  0.063639   \n",
       "4     0.220945  0.070169 -0.045384 -0.023608 -0.403638 -0.047966  0.021852   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3254  0.083572  0.117578 -0.050548 -0.240905 -0.065884  0.097666 -0.186384   \n",
       "3255  0.041132  0.226143 -0.060794 -0.271573 -0.233932  0.017458  0.101868   \n",
       "3256  0.176898  0.235542 -0.309587 -0.118536 -0.236206  0.157906  0.145540   \n",
       "3257 -0.021237  0.263314 -0.019418 -0.325118 -0.068818 -0.095046  0.113397   \n",
       "3258 -0.023487  0.140248  0.096510 -0.230313 -0.297580 -0.073714 -0.069468   \n",
       "\n",
       "          97.1      98.1      99.1  \n",
       "0    -0.296446  0.236455  0.319731  \n",
       "1    -0.108647  0.454259  0.123385  \n",
       "2    -0.169493  0.404920  0.206606  \n",
       "3     0.030749  0.490816  0.076445  \n",
       "4    -0.119835  0.352950  0.071742  \n",
       "...        ...       ...       ...  \n",
       "3254 -0.357412  0.373521  0.311909  \n",
       "3255  0.061758  0.432194  0.132932  \n",
       "3256 -0.052904  0.599252 -0.017703  \n",
       "3257  0.029055  0.335391  0.223715  \n",
       "3258 -0.119313  0.249925  0.050214  \n",
       "\n",
       "[3259 rows x 307 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv(\"model_data_4.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax: droping y/target variable then use remainder with ->> df.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data in train test set using scikitlearn tr-t-s() funtion and  syntax below:\n",
    "train, test = train_test_split(df, test_size=0.3, random_state=42)        # 30% test set split\n",
    "X_train = train.drop(['target'], axis=1).values     #should remain 306 features\n",
    "X_test = test.drop(['target'], axis=1).values\n",
    "y_train = train['target']\n",
    "y_test = test['target']\n",
    "\n",
    "# Or Alternatively:::\n",
    "# use pandas sampling funtion to Split Data into Training and test sets:\n",
    "# df_copy = df.copy()\n",
    "# df_train = df_copy.sample(frac=0.70, random_state=1)\n",
    "# df_test = df_copy.drop(df_train.index)\n",
    "# \n",
    "# print(df_train.shape)\n",
    "# print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2281, 306)\n",
      "(978, 306)\n",
      "(2281,)\n",
      "(978,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) \n",
    "print(X_test.shape)\n",
    "print(y_train.shape) \n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# observe distribution to see if labels are unbalanced and need undersampling/Oversampling techniques applied \n",
    "train['target'].value_counts().plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEBCAYAAACDu+UiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAARfUlEQVR4nO3dbYxcV33H8e8PkwZaQCTKJjW2i1NqqjoUjLQYVKSKEkTcQOtQEeQIIgulMi8SCSREZaNKQCVLoeKhfdFQDERYLZBaBRQL6EMwUEQLMRsIIY6xsEiIF1vx8qRA1bq18++LuSmDPd6d3dnxxMffjzSae889585/da3fXp+9d26qCklSW5406QIkScvPcJekBhnuktQgw12SGmS4S1KDnjzpAgAuu+yyWrt27aTLkKTzyj333PPDqpoatO0JEe5r165lZmZm0mVI0nklyffPts1pGUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJatAT4g7Vc23t9s9OuoSxeujWV026BEkT5pm7JDXIcJekBhnuktQgw12SGjR0uCdZkeSbST7TrV+a5K4k3+3eL+nruyPJ4SSHklwzjsIlSWe3mDP3NwMH+9a3A/uqah2wr1snyXpgC3AVsAm4LcmK5SlXkjSMocI9yWrgVcCH+5o3A7u75d3AdX3td1TViap6EDgMbFyWaiVJQxn2zP2vgD8DHutru6KqjgF075d37auAI339Zru2X5JkW5KZJDNzc3OLrVuSNI8Fwz3Jq4HjVXXPkPvMgLY6o6FqV1VNV9X01NTARwBKkpZomDtUXwr8cZJrgacAz0jy98AjSVZW1bEkK4HjXf9ZYE3f+NXA0eUsWpI0vwXP3KtqR1Wtrqq19P5Q+oWqegOwF9jaddsK3Nkt7wW2JLk4yZXAOmD/slcuSTqrUb5b5lZgT5KbgIeB6wGq6kCSPcADwEng5qo6NXKlkqShLSrcq+pLwJe65R8BV5+l305g54i1SZKWyDtUJalBhrskNchwl6QGGe6S1CDDXZIadEE+Zk/nNx+TKC3MM3dJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDRrmAdlPSbI/ybeSHEjyrq79nUl+kOTe7nVt35gdSQ4nOZTkmnH+AJKkMw3z3TIngJdX1c+TXAR8Jck/ddveX1Xv6e+cZD29Z61eBTwL+HyS5/qoPUk6d4Z5QHZV1c+71Yu6V80zZDNwR1WdqKoHgcPAxpErlSQNbag59yQrktwLHAfuqqq7u023JLkvye1JLunaVgFH+obPdm2n73NbkpkkM3Nzc0v/CSRJZxgq3KvqVFVtAFYDG5M8D/gA8BxgA3AMeG/XPYN2MWCfu6pquqqmp6amllC6JOlsFnW1TFX9FPgSsKmqHulC/zHgQ/xi6mUWWNM3bDVwdPRSJUnDGuZqmakkz+yWnwq8AvhOkpV93V4D3N8t7wW2JLk4yZXAOmD/slYtSZrXMFfLrAR2J1lB75fBnqr6TJK/S7KB3pTLQ8CbAKrqQJI9wAPASeBmr5SRpHNrwXCvqvuAFw5ov3GeMTuBnaOVJklaKu9QlaQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aJjH7D0lyf4k30pyIMm7uvZLk9yV5Lvd+yV9Y3YkOZzkUJJrxvkDSJLONMyZ+wng5VX1AmADsCnJS4DtwL6qWgfs69ZJsh7YAlwFbAJu6x7RJ0k6RxYM9+r5ebd6UfcqYDOwu2vfDVzXLW8G7qiqE1X1IHAY2LicRUuS5jfUnHuSFUnuBY4Dd1XV3cAVVXUMoHu/vOu+CjjSN3y2azt9n9uSzCSZmZubG+FHkCSdbqhwr6pTVbUBWA1sTPK8ebpn0C4G7HNXVU1X1fTU1NRQxUqShrOoq2Wq6qfAl+jNpT+SZCVA93686zYLrOkbtho4OmqhkqThDXO1zFSSZ3bLTwVeAXwH2Ats7bptBe7slvcCW5JcnORKYB2wf5nrliTN48lD9FkJ7O6ueHkSsKeqPpPkq8CeJDcBDwPXA1TVgSR7gAeAk8DNVXVqPOVLkgZZMNyr6j7ghQPafwRcfZYxO4GdI1cnSVoS71CVpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQcM8iWlNki8mOZjkQJI3d+3vTPKDJPd2r2v7xuxIcjjJoSTXjPMHkCSdaZgnMZ0E3lpV30jydOCeJHd1295fVe/p75xkPbAFuAp4FvD5JM/1aUySdO4seOZeVceq6hvd8s+Ag8CqeYZsBu6oqhNV9SBwGNi4HMVKkoazqDn3JGvpPXLv7q7pliT3Jbk9ySVd2yrgSN+wWeb/ZSBJWmZDh3uSpwGfBN5SVY8CHwCeA2wAjgHvfbzrgOE1YH/bkswkmZmbm1ts3ZKkeQwV7kkuohfsH6uqTwFU1SNVdaqqHgM+xC+mXmaBNX3DVwNHT99nVe2qqumqmp6amhrlZ5AknWaYq2UCfAQ4WFXv62tf2dftNcD93fJeYEuSi5NcCawD9i9fyZKkhQxztcxLgRuBbye5t2t7O3BDkg30plweAt4EUFUHkuwBHqB3pc3NXikjSefWguFeVV9h8Dz65+YZsxPYOUJdkqQReIeqJDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBwzxmb02SLyY5mORAkjd37ZcmuSvJd7v3S/rG7EhyOMmhJNeM8weQJJ1pmDP3k8Bbq+p3gJcANydZD2wH9lXVOmBft063bQtwFbAJuC3JinEUL0kabMFwr6pjVfWNbvlnwEFgFbAZ2N112w1c1y1vBu6oqhNV9SBwGNi4zHVLkuaxqDn3JGuBFwJ3A1dU1THo/QIALu+6rQKO9A2b7dokSefI0OGe5GnAJ4G3VNWj83Ud0FYD9rctyUySmbm5uWHLkCQNYahwT3IRvWD/WFV9qmt+JMnKbvtK4HjXPgus6Ru+Gjh6+j6raldVTVfV9NTU1FLrlyQNMMzVMgE+Ahysqvf1bdoLbO2WtwJ39rVvSXJxkiuBdcD+5StZkrSQJw/R56XAjcC3k9zbtb0duBXYk+Qm4GHgeoCqOpBkD/AAvSttbq6qU8tduCTp7BYM96r6CoPn0QGuPsuYncDOEeqSJI3AO1QlqUGGuyQ1yHCXpAYZ7pLUoGGulpGkZbF2+2cnXcJYPXTrqyZdwv/zzF2SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQMI/Zuz3J8ST397W9M8kPktzbva7t27YjyeEkh5JcM67CJUlnN8yZ+0eBTQPa319VG7rX5wCSrAe2AFd1Y25LsmK5ipUkDWfBcK+qLwM/HnJ/m4E7qupEVT0IHAY2jlCfJGkJRplzvyXJfd20zSVd2yrgSF+f2a7tDEm2JZlJMjM3NzdCGZKk0y013D8APAfYABwD3tu1D3qQdg3aQVXtqqrpqpqemppaYhmSpEGWFO5V9UhVnaqqx4AP8Yupl1lgTV/X1cDR0UqUJC3WksI9ycq+1dcAj19JsxfYkuTiJFcC64D9o5UoSVqsBR+zl+QTwMuAy5LMAu8AXpZkA70pl4eANwFU1YEke4AHgJPAzVV1aiyVS5LOasFwr6obBjR/ZJ7+O4GdoxQlSRqNd6hKUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhq0YLgnuT3J8ST397VdmuSuJN/t3i/p27YjyeEkh5JcM67CJUlnN8yZ+0eBTae1bQf2VdU6YF+3TpL1wBbgqm7MbUlWLFu1kqShLBjuVfVl4MenNW8GdnfLu4Hr+trvqKoTVfUgcBjYuDylSpKGtdQ59yuq6hhA9355174KONLXb7ZrO0OSbUlmkszMzc0tsQxJ0iDL/QfVDGirQR2raldVTVfV9NTU1DKXIUkXtqWG+yNJVgJ078e79llgTV+/1cDRpZcnSVqKpYb7XmBrt7wVuLOvfUuSi5NcCawD9o9WoiRpsZ68UIcknwBeBlyWZBZ4B3ArsCfJTcDDwPUAVXUgyR7gAeAkcHNVnRpT7ZKks1gw3KvqhrNsuvos/XcCO0cpSpI0Gu9QlaQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aMGHdcwnyUPAz4BTwMmqmk5yKfAPwFrgIeB1VfWT0cqUJC3Gcpy5/0FVbaiq6W59O7CvqtYB+7p1SdI5NI5pmc3A7m55N3DdGD5DkjSPUcO9gH9Nck+SbV3bFVV1DKB7v3zQwCTbkswkmZmbmxuxDElSv5Hm3IGXVtXRJJcDdyX5zrADq2oXsAtgenq6RqxDktRnpDP3qjravR8HPg1sBB5JshKgez8+apGSpMVZcrgn+bUkT398GXglcD+wF9jaddsK3DlqkZKkxRllWuYK4NNJHt/Px6vqn5N8HdiT5CbgYeD60cuUJC3GksO9qr4HvGBA+4+Aq0cpSpI0Gu9QlaQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1aGzhnmRTkkNJDifZPq7PkSSdaSzhnmQF8DfAHwLrgRuSrB/HZ0mSzjSuM/eNwOGq+l5V/Q9wB7B5TJ8lSTrNKA/Ins8q4Ejf+izw4v4OSbYB27rVnyc5NKZangguA354rj4s7z5Xn3TB8Pidv1o/ds8+24ZxhXsGtNUvrVTtAnaN6fOfUJLMVNX0pOvQ0nj8zl8X8rEb17TMLLCmb301cHRMnyVJOs24wv3rwLokVyb5FWALsHdMnyVJOs1YpmWq6mSSW4B/AVYAt1fVgXF81nnigph+apjH7/x1wR67VNXCvSRJ5xXvUJWkBhnuktQgw12SGmS4S1KDDPcxSfKXSZ6R5KIk+5L8MMkbJl2XpAuD4T4+r6yqR4FX07up67nA2yZbkoaV5GdJHj3tdSTJp5P85qTr09mdduz+O8mpJI9Ouq5zbVxfPyC4qHu/FvhEVf04GfStDHqCeh+9u6o/Tu/rNLYAvw4cAm4HXjaxyjSvqnp6/3qS6+h9meEFxevcxyTJrcB1wH/R+4f1TOAzVfXieYbpCSLJ3acfqyRfq6qXJPlWVb1gUrVp8R4/dpOu41zyzH1Mqmp7kncDj1bVqST/iV97fD55LMnrgH/s1l/bt80zoiewJH/St/okYJoL8JgZ7mOS5CLgRuD3u+mYfwP+dqJFaTFeD/w1cBu9YPga8IYkTwVumWRhWtAf9S2fBB7iAjyxclpmTJJ8mN68++6u6UbgVFX96eSqknSh8GqZ8XlRVW2tqi90rzcCL5p0URpOkud2l7De360/P8mfT7ouLcxj12O4j8+pJM95fKW7fO7UBOvR4nwI2AH8L0BV3Ufvihk98XnscM59nN4GfDHJ97r1tcAbJ1eOFulXq2r/aZevnpxUMVoUjx2euY/TvwMfBB7rXh8EvjrRirQYP+z+51UASV4LHJtsSRqSxw7/oDo2SfYAjwIf65puAC6pqusnV5WG1U2j7QJ+D/gJ8CDw+qr6/kQL04I8dj2G+5gMutHFm1/OH0kupndt+1rgUnq/qKuq/mKSdWlhHrse59zH55tJXlJVXwNI8mJ6UzU6P9wJ/BT4Bj7c/XzjscMz97FJchD4beDhruk3gIP05t+rqp4/qdq0sCT3V9XzJl2HFs9j1+OZ+/hsmnQBGsl/JPndqvr2pAvRonns8MxdGijJA8Bv0ftj3Al63wzp/7jOAx67HsNdGiDJswe1X2hXXJyPPHY9hrskNcibmCSpQYa7JDXIcJekBhnuktSg/wNZgOS44Dt3TwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['target'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> SVM(support Vector Machine) Model ::: </h3>\n",
    "\n",
    "<p> S/N:: Logistic regression implemtation may need one-hot-encoded target variables because y variable contains >2 multiclass labels\n",
    " Different parameters from default will need to be applied due to multiclass label\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Accuracy: Mean:0.6576055312954876   S.D: 0.031538489457216906\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import model_selection           #for implementing cross validation\n",
    "\n",
    "svc = svm.SVC(kernel='linear', C=1, probability=True)     # Initiate SVM model\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, shuffle=True, random_state=7)   # 10 K-fold Cross validation\n",
    "\n",
    "cv_results = model_selection.cross_val_score(svc, X_train, y_train, cv=kfold, scoring='accuracy')  # results\n",
    "\n",
    "print(f\"SVM Model Accuracy: Mean:{cv_results.mean()}   S.D: {cv_results.std()}\")\n",
    "\n",
    "## training the model\n",
    "#prediction = svc.predict_proba(xvalid_bow) \n",
    "#prediction_int = prediction[:,1] >= 0.3 \n",
    "#prediction_int = prediction_int.astype(np.int) \n",
    "#f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Random Forest Classifier ::: </h3>\n",
    "\n",
    "S/N: Micro- and macro-averages (for whatever metric) will compute slightly different things, and thus their interpretation differs. A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forrest Model Accuracy: Mean:0.9943001608825558   S.D: 0.003948010973404544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=400, random_state=11)\n",
    "\n",
    "rf_results = model_selection.cross_val_score(rf, X_train, y_train, cv=kfold, scoring='accuracy') \n",
    "\n",
    "print(f\"Random Forrest Model Accuracy: Mean:{rf_results.mean()}   S.D: {rf_results.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> MultiLayer Perceptron (MLP) ::: </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malik\\miniconda3\\envs\\tensor2.5\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\malik\\miniconda3\\envs\\tensor2.5\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\malik\\miniconda3\\envs\\tensor2.5\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multlayer Perceptron Model Accuracy: Mean: 0.7295602543476596  S.D: 0.13301088995562096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data  \n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "# Transform X train data\n",
    "X_train = scaler.transform(X_train)  \n",
    "# Transform X test data\n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(2,3), max_iter=2000, activation='logistic')\n",
    "\n",
    "mlp_results = model_selection.cross_val_score(mlp, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print(f\"Multlayer Perceptron Model Accuracy: Mean: {mlp_results.mean()}  S.D: {mlp_results.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malik\\miniconda3\\envs\\tensor2.5\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'activation': 'logistic', 'hidden_layer_sizes': (3,), 'max_iter': 2000, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Implementing Grid Search to explore the hyperparameters on MLP\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "        {\n",
    "            'activation' : ['identity', 'logistic'],\n",
    "            'solver' : ['lbfgs', 'adam'],\n",
    "            'hidden_layer_sizes': [\n",
    "             (1,2),(2,3),(3,),(4,),(5,),(10,),(12,4),(16,2),(17,),(18,),(20,)\n",
    "             ],\n",
    "            'max_iter' : [2000]\n",
    "        }\n",
    "       ]\n",
    "\n",
    "clf = GridSearchCV(MLPClassifier(), param_grid, cv=3,\n",
    "                           scoring='accuracy')\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', hidden_layer_sizes=(3,), max_iter=2000)\n",
      "1.0\n",
      "{'activation': 'logistic', 'hidden_layer_sizes': (3,), 'max_iter': 2000, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#clf.cv_results_ \n",
    "bestModel = clf.best_estimator_\n",
    "print(bestModel)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = MLPClassifier(solver='adam', hidden_layer_sizes=(12, 4), max_iter=2000, activation='logistic').fit(X_train,y_train)\n",
    "y_pred = mlp2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Evaluation Metrics for 'final selected model'</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model F1 Score is: 1.0\n",
      "Model Accuracy is: 1.0\n",
      "Model Precision is: 1.0\n",
      "Model Recall is: 1.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       1.00      1.00      1.00       379\n",
      "         neu       1.00      1.00      1.00       182\n",
      "         pos       1.00      1.00      1.00       417\n",
      "\n",
      "    accuracy                           1.00       978\n",
      "   macro avg       1.00      1.00      1.00       978\n",
      "weighted avg       1.00      1.00      1.00       978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(f\"Model F1 Score is: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "print(f\"Model Accuracy is: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Model Precision is: {metrics.precision_score(y_test, y_pred, average='micro')}\")\n",
    "print(f\"Model Recall is: {metrics.recall_score(y_test, y_pred, average='macro')}\")\n",
    "print(end='\\n')\n",
    "\n",
    "# Return Sturctured Classification Report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a confusion Matrix plot\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=mlp2.classes_) #can add normalise args (normalize='all'/'pred'/'true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "import pickle\n",
    "pickle.dump(mlp2, open(\"savedmodel.sav\", 'wb'))\n",
    "\n",
    "## some time later...\n",
    "## load the model from disk\n",
    "#rf2 = pickle.load(open(\"savedmodel.sav\", 'rb'))\n",
    "#pred = mlp2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "It can be observed that both Random Forest and Neural Network(MLP) models performs well compared to linear support vector machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations and other considerations\n",
    "\n",
    "A lot has been considerd in this research but still there is plenty of room for other things to try out.\n",
    "\n",
    "We have built so many models, we can definitely try model ensembling.\n",
    "\n",
    "Take out Parts-of-Speech tagging and try creating with new features with stemming or without any stem/lemma.\n",
    "\n",
    "Use bi-grams or tri-grams (tokens of 2 or 3 words respectively) for Bag-of-Words and TF-IDF then build models using these features\n",
    "\n",
    "We can give pretrained word-embeddings models a try as the embedding learned from the data is not very accurate and doesn't perform well without the additional features\n",
    "\n",
    "<p>Others: Try implementing LTSM Neural Network using logic demonstated <a href:\"https://www.kaggle.com/kritanjalijain/twitter-sentiment-analysis-lstm\"> on this Kaggle Notebook </a></p>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "035b9c71e4a3a67db39a7728b05f0df5cc8b8760f61dc7a461f1625dbaae32b6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tensor2.5': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
